{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/06/unsupervised-deep-learning-computer-vision/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 1s 44us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 247s 9us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 41s 9us/step\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (val_x, val_y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.\n",
    "val_x = val_x/255.\n",
    "\n",
    "train_x = train_x.reshape(-1, 784)\n",
    "val_x = val_x.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(2000, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(500, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(2000, activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0912 - val_loss: 0.0690\n",
      "Epoch 2/500\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0606 - val_loss: 0.0493\n",
      "Epoch 3/500\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0429 - val_loss: 0.0384\n",
      "Epoch 4/500\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0384 - val_loss: 0.0348\n",
      "Epoch 5/500\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0329 - val_loss: 0.0307\n",
      "Epoch 6/500\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0295 - val_loss: 0.0280\n",
      "Epoch 7/500\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0268 - val_loss: 0.0257\n",
      "Epoch 8/500\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0248 - val_loss: 0.0240\n",
      "Epoch 9/500\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0238 - val_loss: 0.0231\n",
      "Epoch 10/500\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0227 - val_loss: 0.0223\n",
      "Epoch 11/500\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 12/500\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0210 - val_loss: 0.0222\n",
      "Epoch 13/500\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0204 - val_loss: 0.0199\n",
      "Epoch 14/500\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 15/500\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 16/500\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 17/500\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 18/500\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 19/500\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 20/500\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 21/500\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0174 - val_loss: 0.0170\n",
      "Epoch 22/500\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 23/500\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0167 - val_loss: 0.0163\n",
      "Epoch 24/500\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 25/500\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 26/500\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0155 - val_loss: 0.0156\n",
      "Epoch 27/500\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 28/500\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 29/500\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 30/500\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 31/500\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 32/500\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 33/500\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 34/500\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 35/500\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 36/500\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 37/500\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 38/500\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 39/500\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0135 - val_loss: 0.0139\n",
      "Epoch 40/500\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 41/500\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 42/500\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 43/500\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 44/500\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 45/500\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 46/500\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 47/500\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0130 - val_loss: 0.0134\n",
      "Epoch 48/500\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 49/500\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 50/500\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0128 - val_loss: 0.0131\n",
      "Epoch 51/500\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 52/500\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 53/500\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0126 - val_loss: 0.0130\n",
      "Epoch 54/500\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 55/500\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 56/500\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 57/500\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 58/500\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 59/500\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 60/500\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 61/500\n",
      "28672/60000 [=============>................] - ETA: 4s - loss: 0.0122"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2674d1d6f014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(train_x, train_x, epochs=500, batch_size=2048, validation_data=(val_x, val_x), callbacks=[estop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1482b35f8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14823bef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pred[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1483524e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x148288940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val_x[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. ENCODE IMAGE using AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layers \n",
    "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
    "  # create an empty model\n",
    "    new_model = Sequential()\n",
    "    for ix in range(starting_layer_ix, ending_layer_ix + 1):\n",
    "        curr_layer = main_model.get_layer(index=ix)\n",
    "        # copy this layer over to the new model\n",
    "        new_model.add(curr_layer)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              1570000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               5500      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784)               1568784   \n",
      "=================================================================\n",
      "Total params: 5,652,794\n",
      "Trainable params: 5,652,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = extract_layers(autoencoder, 0 , 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2000)              1570000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 2,826,010\n",
      "Trainable params: 2,826,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding1 = model1.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20656303, 0.5694029 , 0.82862675, 0.36750895, 0.3586441 ,\n",
       "       0.3731063 , 0.2785989 , 0.5573358 , 0.5689776 , 0.2379938 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENOISING AUTOENCODER (Image Denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 150 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (6.0.0)\n",
      "Collecting Shapely\n",
      "  Downloading Shapely-1.7.0-cp36-cp36m-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 99 kB/s eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (4.0.0.21)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (1.17.3)\n",
      "Requirement already satisfied: matplotlib in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (2.1.0)\n",
      "Requirement already satisfied: scipy in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (1.2.2)\n",
      "Requirement already satisfied: imageio in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (2.4.1)\n",
      "Requirement already satisfied: six in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from imgaug) (1.13.0)\n",
      "Collecting scikit-image>=0.14.2\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-macosx_10_13_x86_64.whl (12.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.1 MB 449 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.7.4-py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 151 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-macosx_10_9_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 417 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from scikit-image>=0.14.2->imgaug) (2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/ritesh.ratti/anaconda3/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.3.0)\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement keras==2.2.4, but you'll have keras 2.2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement numpy==1.15.4, but you'll have numpy 1.17.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement pandas==0.23.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement requests==2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement scikit-image==0.14.2, but you'll have scikit-image 0.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement scikit-learn==0.20.2, but you'll have scikit-learn 0.21.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement scipy==1.2.0, but you'll have scipy 1.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement tensorflow==1.12.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: autokeras 0.3.7 has requirement tqdm==4.29.1, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: skater 1.1.2 has requirement scikit-image==0.14, but you'll have scikit-image 0.17.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Shapely, tifffile, PyWavelets, scikit-image, imgaug\n",
      "  Attempting uninstall: PyWavelets\n",
      "    Found existing installation: PyWavelets 1.0.1\n",
      "    Uninstalling PyWavelets-1.0.1:\n",
      "      Successfully uninstalled PyWavelets-1.0.1\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.14.0\n",
      "    Uninstalling scikit-image-0.14.0:\n",
      "      Successfully uninstalled scikit-image-0.14.0\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.0 imgaug-0.4.0 scikit-image-0.17.2 tifffile-2020.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "seq = iaa.Sequential([iaa.SaltAndPepper(0.2)])\n",
    "\n",
    "train_x_aug = seq.augment_images(train_x)\n",
    "val_x_aug = seq.augment_images(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.\n",
    "val_x = val_x/255.\n",
    "\n",
    "train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "val_x = val_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_x_aug = train_x_aug/255.\n",
    "val_x_aug = val_x_aug/255.\n",
    "\n",
    "train_x_aug = train_x_aug.reshape(-1, 28, 28, 1)\n",
    "val_x_aug = val_x_aug.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
