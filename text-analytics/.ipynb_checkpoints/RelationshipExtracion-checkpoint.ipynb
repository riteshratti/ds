{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is sample code for relation detection piece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ritesh.ratti/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REL_DETECT_CORPUS = open ( \"rel_detect_corpus_2.txt\")\n",
    "\n",
    "sentence_in_corpus=[]\n",
    "tag_in_sentence=[]\n",
    "\n",
    "#read all the corpus\n",
    "while(1):\n",
    "    line= REL_DETECT_CORPUS.readline() #reads all sentence_in_corpus and tag_in_sentence\n",
    "    if line=='':\n",
    "        break\n",
    "    if(line[0]!='{' and len(line)>5):\n",
    "        sentence_in_corpus.append(line)\n",
    "    elif line[0]=='{':\n",
    "        tag_in_sentence.append(line)\n",
    "    \n",
    "REL_DETECT_CORPUS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Israel television rejected a skit by comedian Tuvia Tzafir that attacked public apathy by depicting an Israeli family watching TV while a fire raged outside .\n",
      "\n",
      "{[Person:Tuvia Tzafir] <4:positive: > [Location:Israel]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sentence_in_corpus[0])\n",
    "print(tag_in_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sentence = the input text\n",
    "# tag = the next line which has the tagged entities and the relation between the entities\n",
    "# return value = the POS tags for the part of sentence which comes in between these entities and flag if entities are flipped\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "tagger = PerceptronTagger() \n",
    "\n",
    "def pos_between_entities(sentence,tag): \n",
    "    flipped=0\n",
    "    \n",
    "    name1=tag[tag.find('['):tag[0].find(']')].split(':')[1]\n",
    "    name1=name1[0:-4]\n",
    "    name2=''\n",
    "    end_ind=tag.find('}')\n",
    "    end_ind=end_ind-1;\n",
    "    i=end_ind;\n",
    "    while(tag[i]!=':'):\n",
    "        i=i-1\n",
    "        name2=name2+tag[i]\n",
    "    name2=name2[::-1]\n",
    "    name2=name2[1:]\n",
    "    \n",
    "    #print tag , entity1, name1, name2\n",
    "    \n",
    "    start=sentence.find(name1)\n",
    "    end=sentence.find(name2)\n",
    "    if(start>end):\n",
    "        flipped=1\n",
    "        temp=start;\n",
    "        start=end;\n",
    "        end=temp\n",
    "    if flipped==1:\n",
    "        start=start+len(name2)+1\n",
    "    else:\n",
    "        start=start+len(name1)+1\n",
    "        \n",
    "    between_text=sentence[start:end]\n",
    "    \n",
    "    #print start \n",
    "    #print end\n",
    "    #print between_text\n",
    "    #if flipped :\n",
    "    #    print sentence\n",
    "    #    print tag\n",
    "    #    print '------------'\n",
    "   \n",
    "    text = word_tokenize(between_text)#tokenize\n",
    "    tagged= tagger.tag(text)#do POS tagging\n",
    "    \n",
    "    pos_tags =''\n",
    "    for word in tagged:\n",
    "        pos_tags=pos_tags+' '+word[1]\n",
    "    \n",
    "    return pos_tags , flipped\n",
    "\n",
    "def tagged_entities (tag):\n",
    "    entity1 = tag[2:tag.find(':')]\n",
    "    entity2 = tag[tag.find('> [')+3:]\n",
    "    entity2 = entity2[:entity2.find(':')]\n",
    "    \n",
    "    return entity1, entity2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_names=[]\n",
    "number_of_sample_to_take = len(sentence_in_corpus)\n",
    "for i in range(0,number_of_sample_to_take):\n",
    "    tag =  tag_in_sentence[i]\n",
    "    entity1,entity2 = tagged_entities(tag)\n",
    "    temp_pos_tag = pos_between_entities(sentence_in_corpus[i],tag)\n",
    "    final_tag= entity1+ ' ' + entity2 + temp_pos_tag[0] + ' ' + str( temp_pos_tag[1] )\n",
    "    rel_result=tag[tag.find('<')+3:tag.find('>')-2]\n",
    "    label = final_tag , rel_result\n",
    "    labeled_names.append(label)\n",
    "\n",
    "#print labeled_names    \n",
    "import random\n",
    "random.shuffle( labeled_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generates features for naive baiyes. accepts a relation , and retruns count of 'CC' and 'VB' in a dictionary form.\n",
    "\n",
    "def extract_features(word): \n",
    "    #print word\n",
    "    new_word=''\n",
    "    tags=word.split(' ')\n",
    "    distance = len(tags) - 3 \n",
    "    for item in tags:\n",
    "        if item=='':\n",
    "            tags.remove(item)\n",
    "                \n",
    "    new_word2=tags.count('CC')\n",
    "    new_word=tags.count('VB') + tags.count('VBD') + tags.count('VBG')+ tags.count('VBN')\n",
    "    # Add following in feature set\n",
    "    #1)POS tag and their count\n",
    "    #2)Entity type \n",
    "    #3)Distance between the entities\n",
    "    return {'rel_type': tags[0][0]+tags[1][0], # rel_type = relation_type\n",
    "            'e1': tags[0],'e2': tags[1],  # e1 = entity1 , e2 = entity2\n",
    "            'ps1': new_word,'ps2':new_word2,# ps1 = pos1_count , ps2 = pos2_count\n",
    "            'ed':distance, #ed = entity_distance\n",
    "            #'flipped': tags[distance+2]\n",
    "           }\n",
    "'''\n",
    "def extract_features(word): \n",
    "    #print word\n",
    "    tags= word.split(' ')\n",
    "    pos = tags[2: len(tags) -1]\n",
    "    distance = len(tags) - 3 \n",
    "    # Add following in feature set\n",
    "    #1)POS tag and their count\n",
    "    #2)Entity type \n",
    "    #3)Distance between the entities\n",
    "    return {'rel_type': tags[0][0]+tags[1][0], # rel_type = relation_type\n",
    "            'e1': tags[0],'e2': tags[1],  # e1 = entity1 , e2 = entity2\n",
    "            'ps1' = pos1_count , ps2 = pos2_count\n",
    "            'ed':distance, #ed = entity_distance\n",
    "            'flipped': tags[distance+2]\n",
    "           }\n",
    "'''\n",
    "def scale_features(featureset): \n",
    "    num_features = len (featureset)\n",
    "    #print num_features\n",
    "    max_pos1_count = 0\n",
    "    max_pos2_count = 0\n",
    "    max_distance = 0\n",
    "    \n",
    "    min_pos1_count = 0\n",
    "    min_pos2_count = 0\n",
    "    min_distance = 0\n",
    "    \n",
    "    for k in range (0 , num_features):\n",
    "        ans = featuresets[k][0]\n",
    "        \n",
    "        if ( max_pos1_count < ans['ps1'] ):\n",
    "            max_pos1_count = ans['ps1']\n",
    "        elif ( min_pos1_count > ans['ps1'] ):\n",
    "            min_pos1_count = ans['ps1']\n",
    "\n",
    "            \n",
    "        if ( max_pos2_count < ans['ps2'] ):\n",
    "            max_pos2_count = ans['ps2']\n",
    "        elif ( min_pos2_count > ans['ps2'] ):\n",
    "            min_pos2_count = ans['ps2']\n",
    "        \n",
    "        if ( max_distance < ans['ed'] ):\n",
    "            max_distance = ans['ed']\n",
    "        elif ( min_distance > ans['ed'] ):\n",
    "            min_distance = ans['ed']\n",
    " \n",
    "    print(max_pos1_count,max_pos2_count,max_distance)   \n",
    "    print(min_pos1_count,min_pos2_count,min_distance)   \n",
    "    \n",
    "    \n",
    "    for k in range (0 , num_features):\n",
    "        ans = featuresets[k][0]\n",
    "        ans['ps1'] = float(ans['ps1'] - min_pos1_count )/ float(max_pos1_count-min_pos1_count)\n",
    "        ans['ps2'] = float(ans['ps2'] - min_pos2_count )/ float(max_pos2_count-min_pos2_count)\n",
    "        ans['ed'] = float(ans['ed'] - min_distance )/ float(max_distance-min_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make the feature set ( this is key value pair)\n",
    "featuresets = [(extract_features(n), rel_result) for (n, rel_result) in labeled_names]\n",
    "#scale_features(featuresets)\n",
    "#print featuresets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n"
     ]
    }
   ],
   "source": [
    "print(number_of_sample_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2266.6666666666665"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*number_of_sample_to_take/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classifier accuracy percent: 69.84687868080094\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[0:int(number_of_sample_to_take*0.75)], featuresets[int(number_of_sample_to_take*0.75) + 1:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "print(\"Naive Bayes classifier accuracy percent:\", (nltk.classify.accuracy(classifier, test_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier accuracy percent: 68.31566548881037\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(train_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, test_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 67.13780918727915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(train_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, test_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |   n   p |\n",
      "         |   e   o |\n",
      "         |   g   s |\n",
      "         |   a   i |\n",
      "         |   t   t |\n",
      "         |   i   i |\n",
      "         |   v   v |\n",
      "         |   e   e |\n",
      "---------+---------+\n",
      "negative |<247>182 |\n",
      "positive |  87<333>|\n",
      "---------+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "error = 10.247349823321555%\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 12}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 5, 'ps2': 1, 'ed': 25}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 4, 'ps2': 1, 'ed': 34}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 0, 'ps2': 1, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 3, 'ps2': 1, 'ed': 29}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 9}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 21}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 3, 'ps2': 0, 'ed': 17}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 18}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 14}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 1, 'ps2': 0, 'ed': 19}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 19}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 9}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 3}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 3}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 3, 'ps2': 0, 'ed': 15}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 19}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 4}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 3, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 7}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 1, 'ps2': 0, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 7}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 20}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 4}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 2, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 3, 'ps2': 1, 'ed': 21}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 3, 'ps2': 1, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 2, 'ed': 42}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 15}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 6, 'ps2': 1, 'ed': 29}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 14}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 1, 'ps2': 0, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 0, 'ps2': 1, 'ed': 10}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 5, 'ps2': 1, 'ed': 30}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 3, 'ps2': 1, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 11}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 7}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 15}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 0, 'ps2': 1, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 3, 'ps2': 1, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 3, 'ps2': 1, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 9}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 2, 'ed': 29}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 2, 'ps2': 0, 'ed': 8}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 3, 'ps2': 0, 'ed': 9}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 9}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 17}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 12}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 2, 'ps2': 0, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 14}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 12}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 1, 'ps2': 0, 'ed': 11}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 7}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 34}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 2, 'ps2': 0, 'ed': 5}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 21}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 25}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 13}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 0, 'ps2': 0, 'ed': 11}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 14}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 1, 'ps2': 1, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 0, 'ps2': 1, 'ed': 6}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 21}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 1, 'ed': 65}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 22}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 5, 'ps2': 0, 'ed': 19}, 'positive')\n",
      "positive negative ({'rel_type': 'PC', 'e1': 'Person', 'e2': 'Company', 'ps1': 2, 'ps2': 0, 'ed': 11}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 1, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'CL', 'e1': 'Company', 'e2': 'Location', 'ps1': 3, 'ps2': 2, 'ed': 28}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 5}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 16}, 'positive')\n",
      "positive negative ({'rel_type': 'PL', 'e1': 'Person', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 22}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 1, 'ps2': 0, 'ed': 5}, 'positive')\n",
      "positive negative ({'rel_type': 'LL', 'e1': 'Location', 'e2': 'Location', 'ps1': 2, 'ps2': 0, 'ed': 11}, 'positive')\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "X_test = [x[0] for x in test_set]\n",
    "y_test = [x[1] for x in test_set]\n",
    "\n",
    "y_pred = SVC_classifier.classify_many( X_test )\n",
    "\n",
    "cm = ConfusionMatrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print('error = '+ \\\n",
    "    str(float(cm['positive','negative'])/\\\n",
    "    (cm['negative','positive']+cm['positive','positive']+cm['negative','negative']+cm['positive','negative'])*100) +\\\n",
    "    '%')\n",
    "\n",
    "\n",
    "for k in range ( 0 , len(y_test)):\n",
    "    if( (y_test [k] != y_pred [k]) and y_test[k] == 'positive'):\n",
    "        print(y_test [k] , y_pred [k] , test_set[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
