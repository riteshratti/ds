{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries required\n",
    "import math\n",
    "import re\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy\n",
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read DAta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the target values from joineddata\n",
    "pdfJoinedFinal = pd.read_csv('joineddata.csv')\n",
    "YData = pdfJoinedFinal.MAIN_PRODUCT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383066"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(YData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features from finalfeatures\n",
    "pdfFeatures = pd.read_csv('finalfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= pdfFeatures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCols = cols.delete([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WAS_USER_DISPUTED', 'DATE_COMPLAINT_USER', 'COMPANY',\n",
       "       'COMPANY_RESPONSE_TO_USER', 'COMPANY_RESPONSE_TO_PUBLIC',\n",
       "       'WAS_RESPONSE_TIMELY', 'DATE_COMPLAINT_COMPANY', 'MAIN_ISSUE',\n",
       "       'SUB_ISSUE', 'DIFF_DATE',\n",
       "       ...\n",
       "       '990', '991', '992', '993', '994', '995', '996', '997', '998', '999'],\n",
       "      dtype='object', length=1013)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'WAS_USER_DISPUTED', 'DATE_COMPLAINT_USER', 'COMPANY',\n",
       "       'COMPANY_RESPONSE_TO_USER', 'COMPANY_RESPONSE_TO_PUBLIC',\n",
       "       'WAS_RESPONSE_TIMELY', 'DATE_COMPLAINT_COMPANY', 'MAIN_ISSUE',\n",
       "       'SUB_ISSUE',\n",
       "       ...\n",
       "       '990', '991', '992', '993', '994', '995', '996', '997', '998', '999'],\n",
       "      dtype='object', length=1014)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfFeatures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFeatures = pdfFeatures[finalCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData = np.asarray(pdfFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XData = XData[:100]\n",
    "YData = YData[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XData, YData, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vectorizer for whole data set\n",
      "Dictonary complete\n",
      "Saving vectorizer model\n"
     ]
    }
   ],
   "source": [
    "# Use Dict Vectorizer for other text content as the number of uniques are limited . \n",
    "# We have already extracted the tf idf vector for complaint text part\n",
    "print('Creating Vectorizer for whole data set')\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "\n",
    "vectorizer_input=[]\n",
    "\n",
    "for eachRow in X_train:\n",
    "    columnNumber = 0\n",
    "    temp_dic={}\n",
    "    for data in eachRow:\n",
    "        temp_dic[str(columnNumber)] = data\n",
    "        columnNumber = columnNumber +1\n",
    "    vectorizer_input.append(temp_dic)\n",
    "print(\"Dictonary complete\")\n",
    "output_all = vectorizer.fit_transform(vectorizer_input)\n",
    "with open('dictvectorizer.pkl', 'wb') as fid:\n",
    "    pickle.dump(vectorizer, fid)\n",
    "\n",
    "print(\"Saving vectorizer model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MAX ABS SCALER for whole data set\n",
      "Saving MAX ABS SCALER model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Creating MAX ABS SCALER for whole data set')\n",
    "maxabsscaler = MaxAbsScaler()\n",
    "output_maxabs=maxabsscaler.fit_transform(output_all)\n",
    "with open('maxscaler.pkl', 'wb') as fid:\n",
    "    pickle.dump(maxabsscaler, fid)\n",
    "\n",
    "print(\"Saving MAX ABS SCALER model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Vectorizer and scaler\n",
    "output = vectorizer.transform(vectorizer_input)\n",
    "\n",
    "output_transformed = maxabsscaler.transform(output.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67441954\n",
      "Iteration 2, loss = 0.67059685\n",
      "Iteration 3, loss = 0.66519900\n",
      "Iteration 4, loss = 0.65845029\n",
      "Iteration 5, loss = 0.65053082\n",
      "Iteration 6, loss = 0.64160978\n",
      "Iteration 7, loss = 0.63185820\n",
      "Iteration 8, loss = 0.62147024\n",
      "Iteration 9, loss = 0.61058513\n",
      "Iteration 10, loss = 0.59931241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(100, 50), max_iter=10,\n",
       "              solver='sgd', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiLayer Perceptron\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                 hidden_layer_sizes=(100,50), verbose=1, max_iter=10)\n",
    "clf.fit(output_transformed, Y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainedmodel.pkl', 'wb') as fid:\n",
    "    pickle.dump(clf, fid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_prediction(prediction,test_sample): #for batch testing\n",
    "    tp=0\n",
    "    if str(prediction) == str(test_sample):\n",
    "        tp=1\n",
    "    return tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.0\n",
      "  (0, 1)\t2019.0\n",
      "  (0, 2)\t0.0\n",
      "  (0, 3)\t0.0\n",
      "  (0, 4)\t0.0\n",
      "  (0, 5)\t0.0\n",
      "  (0, 6)\t0.0\n",
      "  (0, 7)\t0.0\n",
      "  (0, 8)\t0.0\n",
      "  (0, 9)\t0.0\n",
      "  (0, 10)\t0.0\n",
      "  (0, 11)\t0.07849939799028242\n",
      "  (0, 12)\t0.0\n",
      "  (0, 13)\t0.0\n",
      "  (0, 14)\t0.0\n",
      "  (0, 15)\t0.0\n",
      "  (0, 16)\t0.0\n",
      "  (0, 17)\t0.0\n",
      "  (0, 18)\t0.0\n",
      "  (0, 19)\t0.0\n",
      "  (0, 20)\t0.0\n",
      "  (0, 21)\t0.0\n",
      "  (0, 22)\t0.0\n",
      "  (0, 23)\t0.0\n",
      "  (0, 24)\t0.0\n",
      "  :\t:\n",
      "  (0, 1037)\t0.0\n",
      "  (0, 1038)\t0.0\n",
      "  (0, 1039)\t0.0\n",
      "  (0, 1040)\t0.0\n",
      "  (0, 1041)\t0.19104693907333115\n",
      "  (0, 1042)\t0.0\n",
      "  (0, 1043)\t0.0\n",
      "  (0, 1044)\t0.0\n",
      "  (0, 1045)\t0.0\n",
      "  (0, 1046)\t0.0\n",
      "  (0, 1047)\t0.0\n",
      "  (0, 1048)\t0.0\n",
      "  (0, 1049)\t0.0\n",
      "  (0, 1050)\t0.0\n",
      "  (0, 1051)\t0.0\n",
      "  (0, 1052)\t0.0\n",
      "  (0, 1053)\t0.0\n",
      "  (0, 1054)\t0.0\n",
      "  (0, 1055)\t0.0\n",
      "  (0, 1056)\t0.0\n",
      "  (0, 1057)\t0.0\n",
      "  (0, 1058)\t0.0\n",
      "  (0, 1059)\t0.0\n",
      "  (0, 1060)\t0.0\n",
      "  (0, 1061)\t0.0\n",
      "1\n",
      "1\n",
      "Accuracy is : 1.0\n",
      "Time Taken 0.0047228336334228516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "corr=0\n",
    "total=0\n",
    "predictionvalue = []\n",
    "vectorizerlist=[]\n",
    "for j in range(0, 1):\n",
    "    columnNumber = 0\n",
    "    temp_vectorizer=[]\n",
    "    temp_dic={}\n",
    "    for data in X_test[j]:\n",
    "        temp_dic[str(columnNumber)] = data\n",
    "        columnNumber = columnNumber +1\n",
    "    temp_vectorizer.append(temp_dic)\n",
    "    vectorizerlist.append(temp_vectorizer)\n",
    "    \n",
    "    test_raw_transformed = vectorizer.transform(temp_vectorizer)\n",
    "\n",
    "    print(test_raw_transformed)    \n",
    "    test_raw_scaled = maxabsscaler.transform(test_raw_transformed)\n",
    "\n",
    "    \n",
    "    #print(test_raw_scaled.shape)\n",
    "    #test_raw_scaled_sc = sc.transform(test_raw_transformed.toarray())\n",
    "    #test_raw_scaled_robust = robustsc.transform(test_raw_transformed.toarray())\n",
    "    \n",
    "    prediction = clf.predict(test_raw_scaled.toarray()).tolist()\n",
    "    predictionvalue.append(prediction[0])\n",
    "    #print(\"Prediction : \",prediction[0])\n",
    "    #print(\" Actual: \",test_tag[j])\n",
    "    cor=evaluate_prediction(prediction[0],Y_test[j])\n",
    "    corr=corr+cor\n",
    "    #if cor ==1 and str(test_tag[j]) != 'Normal':\n",
    "        #print(test_raw[j])\n",
    "        #print(test_tag[j])\n",
    "    total=total+1\n",
    "print(str(corr))\n",
    "print(str(total))\n",
    "print('Accuracy is : ' + str(float(corr)/total))\n",
    "endTime= time.time()\n",
    "print(\"Time Taken \"+ str(endTime - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5a624f319b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictionvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelSeries\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfo\u001b[0m                         \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!/usr/bin/env python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFrame\u001b[0m       \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSeries\u001b[0m     \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimbaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimbaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnsaccessors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msnsaccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/skaccessors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearModelMethods\u001b[0m                 \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mManifoldMethods\u001b[0m                        \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetricsMethods\u001b[0m                          \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSelectionMethods\u001b[0m           \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskaccessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeighborsMethods\u001b[0m                      \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/skaccessors/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    254\u001b[0m _true_pred_methods = (_classification_methods + _regression_methods\n\u001b[1;32m    255\u001b[0m                       + _cluster_methods)\n\u001b[0;32m--> 256\u001b[0;31m \u001b[0m_attach_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetricsMethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_wrap_target_pred_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_true_pred_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas_ml/core/accessor.py\u001b[0m in \u001b[0;36m_attach_methods\u001b[0;34m(cls, wrap_func, methods)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0m_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} already has '{1}' method\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'jaccard_similarity_score'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = ConfusionMatrix(y_true=Y_test, y_pred=predictionvalue)\n",
    "cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
