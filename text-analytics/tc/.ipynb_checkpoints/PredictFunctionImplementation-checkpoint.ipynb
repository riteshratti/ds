{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries required\n",
    "import math\n",
    "import re\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy\n",
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = pickle.load(open('tfidfvectorizer.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('dictvectorizer.pkl', 'rb'))\n",
    "maxabsscaler = pickle.load(open('maxscaler.pkl', 'rb'))\n",
    "clf = pickle.load(open('trainedmodel.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%m/%d/%Y\")\n",
    "    d2 = datetime.strptime(d2, \"%m/%d/%Y\")\n",
    "    return abs((d2 - d1).days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    parts = text.split(',')\n",
    "    corpus=[]\n",
    "    corpus.append(parts[0])    \n",
    "    #len(tfidfvectorizer.transform(corpus).toarray()[0])\n",
    "    tfidfvec = tfidfvectorizer.transform(corpus).toarray()\n",
    "    finalvec=[]\n",
    "    for i in range(1,len(parts)):\n",
    "        finalvec.append(parts[i])\n",
    "\n",
    "    finalvec.append(days_between (finalvec[1],finalvec[6]))\n",
    "    finalvec.append(datetime.strptime(finalvec[1], \"%m/%d/%Y\").year)\n",
    "    finalvec.append(datetime.strptime(finalvec[1], \"%m/%d/%Y\").month)\n",
    "    finalvec.append(datetime.strptime(finalvec[1], \"%m/%d/%Y\").day)\n",
    "    finalvec = finalvec + (tfidfvec.tolist()[0])\n",
    "    \n",
    "    X_test = finalvec\n",
    "        # Predict Function\n",
    "    columnNumber = 0\n",
    "    temp_vectorizer=[]\n",
    "    predictionvalue = []\n",
    "    vectorizerlist=[]\n",
    "    temp_dic={}\n",
    "    for data in X_test:\n",
    "        temp_dic[str(columnNumber)] = data\n",
    "        columnNumber = columnNumber +1\n",
    "    temp_vectorizer.append(temp_dic)\n",
    "    vectorizerlist.append(temp_vectorizer)\n",
    "    test_raw_transformed = vectorizer.transform(temp_vectorizer)\n",
    "    \n",
    "\n",
    "    prediction = clf.predict(test_raw_transformed.toarray()).tolist()\n",
    "    return prediction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"XXXX Transunion reporting incorrectly I 120 day past due loan XXXX - partial account number XXXX ; XXXX ; XXXX ; XXXX.. These account reflect { $ 0.00 } balance { $ 0.00 } past due . I contacted two bureau requested coding error corrected . This incorrect reporting harming credit score . It impossible past due account { $ 0.00 } balance { $ 0.00 } past due .,0,03/19/2019,TRANSUNION INTERMEDIATE HOLDINGS INC.,Closed explanation,Company ha responded consumer CFPB chooses provide public response,1,03/19/2019,Problem credit reporting company 's investigation existing problem,Their investigation fix error report\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Debt collection']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Debt collection']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
